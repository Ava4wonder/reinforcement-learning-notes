A constantly evolving list of notes and summaries of the Reinforcement Learning papers.

# Deep Reinforcement Learning
## Year 2017
**Programmable Agents**
  - [[arxiv](https://arxiv.org/abs/1706.06383v1)], [[pdf](https://arxiv.org/pdf/1706.06383v1.pdf)]
  - Denil et al.; Google DeepMind

**Hybrid Reward Architecture for Reinforcement Learning**
  - [[arxiv](https://arxiv.org/abs/1706.04208v1)], [[pdf](https://arxiv.org/pdf/1706.04208v1.pdf)]
  - van Seijen et al.; Microsoft Maluuba, McGill University


**Evolution Strategies as a Scalable Alternative to Reinforcement Learning**
  - [[arxiv](https://arxiv.org/abs/1703.03864v1)], [[pdf](https://arxiv.org/pdf/1703.03864v1.pdf)]
  - Tim Salimans et al.; OpenAI

**Neural Episodic Control**
  - [[arXiv](https://arxiv.org/abs/1703.01988v1)], [[pdf](https://arxiv.org/pdf/1703.01988v1.pdf)]
  - Pritzel et al.; Google DeepMind
  - :pencil: [**Notes**](./notes/nec-agent.md)
  - **Brief Summary.** Neural Episidic Control (NEC) agent is extremely data efficient. NEC performance at 5 millions of frames can be reached by DQN with Prior. Replay only after 40 millions of frames. However, the final perfomance is still worse than the other state-of-the-art agents can obtain.

## Year 2016
**UNREAL agent: Reinforcement Learning with unsupervised auxiliary tasks**
  - [[arXiv](https://arxiv.org/abs/1611.05397)], [[pdf](https://arxiv.org/pdf/1611.05397.pdf)]
  - Jaderberg et al.; Google DeepMind
  - :pencil: [**Notes**](./notes/unreal-agent.md)
  
:rocket: **A3C agent: Asynchronous Methods for Deep Reinforcement Learning**
  - [[arXiv](https://arxiv.org/abs/1602.01783v2)], [[pdf](https://arxiv.org/pdf/1602.01783v2.pdf)]
  - Mnih et al.; Google DeepMind
  - :pencil: [**Notes**](./notes/a3c-agent.md)
  
:godmode: **VizDoom 2016 (Full DM) Winner: Learning to act by predicting the future**
  - [[arXiv](https://arxiv.org/abs/1611.01779)], [[pdf](https://arxiv.org/pdf/1611.01779.pdf)]
  - Dosovitskiy, Koltun; Intel Labs
  
:godmode: **VizDoom 2016 (Limited DM) 2nd place: Playing FPS Games with Deep Reinforcement Learning**
  - [[arXiv](https://arxiv.org/abs/1609.05521)], [[pdf](https://arxiv.org/pdf/1609.05521.pdf)]
  - Lample, Chaplot; Carnegie Mellon University

**The Predictron: End-To-End Learning and Planning**
  - [[arXiv](https://arxiv.org/abs/1612.08810v2)], [[pdf](https://arxiv.org/pdf/1612.08810v2.pdf)]
  - Silver et al.; Google DeepMind

## Year 2015
**Prioritized Experience Replay**
  - [[arXiv](https://arxiv.org/abs/1511.05952v4)], [[pdf](https://arxiv.org/pdf/1511.05952v4.pdf)]
  - Schaul et al.; Google DeepMind
  - :pencil: [**Notes**](./notes/prioritized-exp-replay.md)

:rocket: **Human-level control through deep reinforcement learning**
  - [[Nature](http://www.nature.com/nature/journal/v518/n7540/full/nature14236.html)]
  - Mnih et al.; Google Deepmind
  - :pencil: [**Notes**](./notes/dqn-agent.md)
 
:star: **Mastering the game of Go with deep neural networks and tree search**
  - [[Nature](https://www.nature.com/nature/journal/v529/n7587/full/nature16961.html)], [[reddit](https://www.reddit.com/r/MachineLearning/comments/42ytdx/pdf_mastering_the_game_of_go_with_deep_neural/)]
  - Silver et al.; Google Deepmind, Google
