A constantly evolving list of notes and summaries of the Reinforcement Learning papers.

# Deep Reinforcement Learning
## Year 2017
**Emergence of Locomotion Behaviours in Rich Environments**
  - [[arXiv](https://arxiv.org/abs/1707.02286)], [[pdf](https://arxiv.org/pdf/1707.02286.pdf)]
  - Heess et al,; Google DeepMind

[RTS:SC] **Multiagent Bidirectionally-Coordinated Nets for Learning to Play StarCraft Combat Games**
  - [[arXiv](https://arxiv.org/abs/1609.02993)], [[pdf](https://arxiv.org/pdf/1703.10069.pdf)]
  - Peng et al.; Alibaba Group, University College London

**Programmable Agents**
  - [[arXiv](https://arxiv.org/abs/1706.06383v1)], [[pdf](https://arxiv.org/pdf/1706.06383v1.pdf)]
  - Denil et al.; Google DeepMind

**Hybrid Reward Architecture for Reinforcement Learning**
  - [[arXiv](https://arxiv.org/abs/1706.04208v1)], [[pdf](https://arxiv.org/pdf/1706.04208v1.pdf)]
  - van Seijen et al.; Microsoft Maluuba, McGill University


**Evolution Strategies as a Scalable Alternative to Reinforcement Learning**
  - [[arXiv](https://arxiv.org/abs/1703.03864v1)], [[pdf](https://arxiv.org/pdf/1703.03864v1.pdf)]
  - Salimans et al.; OpenAI

**Neural Episodic Control**
  - [[arXiv](https://arxiv.org/abs/1703.01988v1)], [[pdf](https://arxiv.org/pdf/1703.01988v1.pdf)]
  - Pritzel et al.; Google DeepMind
  - :pencil: [**Notes**](./notes/nec-agent.md)
  - **Brief Summary.** Neural Episidic Control (NEC) agent is extremely data efficient. NEC performance at 5 millions of frames can be reached by DQN with Prior. Replay only after 40 millions of frames. However, the final perfomance is still worse than the other state-of-the-art agents can obtain.

## Year 2016
[RTS:SC] **Episodic Exploration for Deep Deterministic Policies: An Application to StarCraft Micromanagement Tasks**
  - [[arXiv](https://arxiv.org/abs/1609.02993)], [[pdf](https://arxiv.org/pdf/1609.02993.pdf)]
  - Usunier et al.; Facebook AI Research

[UNREAL Agent] **Reinforcement Learning with unsupervised auxiliary tasks**
  - [[arXiv](https://arxiv.org/abs/1611.05397)], [[pdf](https://arxiv.org/pdf/1611.05397.pdf)]
  - Jaderberg et al.; Google DeepMind
  - :pencil: [**Notes**](./notes/unreal-agent.md)
  
:rocket: [A3C Agent] **Asynchronous Methods for Deep Reinforcement Learning**
  - [[arXiv](https://arxiv.org/abs/1602.01783v2)], [[pdf](https://arxiv.org/pdf/1602.01783v2.pdf)]
  - Mnih et al.; Google DeepMind
  - :pencil: [**Notes**](./notes/a3c-agent.md)
  
[FPS::godmode:] **VizDoom 2016 (Full DM) Winner: Learning to act by predicting the future**
  - [[arXiv](https://arxiv.org/abs/1611.01779)], [[pdf](https://arxiv.org/pdf/1611.01779.pdf)]
  - Dosovitskiy, Koltun; Intel Labs
  
[FPS::godmode:] **VizDoom 2016 (Limited DM) 2nd place: Playing FPS Games with Deep Reinforcement Learning**
  - [[arXiv](https://arxiv.org/abs/1609.05521)], [[pdf](https://arxiv.org/pdf/1609.05521.pdf)]
  - Lample, Chaplot; Carnegie Mellon University

**The Predictron: End-To-End Learning and Planning**
  - [[arXiv](https://arxiv.org/abs/1612.08810v2)], [[pdf](https://arxiv.org/pdf/1612.08810v2.pdf)]
  - Silver et al.; Google DeepMind

## Year 2015
:star: **Dueling Network Architectures for Deep Reinforcement Learning**
  - [[arXiv](https://arxiv.org/abs/1511.06581)], [[pdf](https://arxiv.org/pdf/1511.06581.pdf)]
  - Wang et al.; Google DeepMind

:star: **Deep Reinforcement Learning with Double Q-learning**
  - [[arXiv](https://arxiv.org/abs/1509.06461)], [[pdf](https://arxiv.org/pdf/1509.06461.pdf)]
  - Hasselt et al.; Google DeepMind

**Prioritized Experience Replay**
  - [[arXiv](https://arxiv.org/abs/1511.05952v4)], [[pdf](https://arxiv.org/pdf/1511.05952v4.pdf)]
  - Schaul et al.; Google DeepMind
  - :pencil: [**Notes**](./notes/prioritized-exp-replay.md)
  

:rocket: **Human-level control through deep reinforcement learning**
  - [[Nature](http://www.nature.com/nature/journal/v518/n7540/full/nature14236.html)]
  - Mnih et al.; Google Deepmind
  - :pencil: [**Notes**](./notes/dqn-agent.md)
 
**Mastering the game of Go with deep neural networks and tree search**
  - [[Nature](https://www.nature.com/nature/journal/v529/n7587/full/nature16961.html)], [[reddit](https://www.reddit.com/r/MachineLearning/comments/42ytdx/pdf_mastering_the_game_of_go_with_deep_neural/)]
  - Silver et al.; Google Deepmind, Google


## 2012 and earlier
**Horde: A Scalable Real-time Architecture for Learning Knowledge from Unsupervised Sensorimotor Interaction**
  - [[pdf](https://www.cs.swarthmore.edu/~meeden/DevelopmentalRobotics/horde1.pdf)]
  - Sutton et al. (2011);  University of Alberta, McGill University
  
:star: [REINFORCE] **Simple Statistical Gradient-Following Algorithms for. Connectionist Reinforcement Learning**
  - [[pdf](http://www-anw.cs.umass.edu/~barto/courses/cs687/williams92simple.pdf)]
  - Ronald J. Williams (1992); Northeastern University
