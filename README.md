A constantly evolving list of notes and summaries of the Reinforcement Learning papers.

# Deep Reinforcement Learning
## Year 2017
**Evolution Strategies as a Scalable Alternative to Reinforcement Learning**
  - [[arxiv](https://arxiv.org/abs/1703.03864v1)], [[pdf](https://arxiv.org/pdf/1703.03864v1.pdf)]
  - Tim Salimans et al.; OpenAI

**Neural Episodic Control**
  - [[arXiv](https://arxiv.org/abs/1703.01988v1)], [[pdf](https://arxiv.org/pdf/1703.01988v1.pdf)]
  - Pritzel et al.; Google DeepMind
  - :pencil: [**Notes**](./notes/nec-agent.md)
  - **Brief Summary.** Neural Episidic Control (NEC) agent is extremely data efficient. NEC performance at 5 millions of frames can be reached by DQN with Prior. Replay only after 40 millions of frames. However, the final perfomance is still worse than the other state-of-the-art agents can obtain.

## Year 2016
**UNREAL agent: Reinforcement Learning with unsupervised auxiliary tasks**
  - [[arXiv](https://arxiv.org/abs/1611.05397)], [[pdf](https://arxiv.org/pdf/1611.05397.pdf)]
  - Jaderberg et al.; Google DeepMind
  - :pencil: [**Notes**](./notes/unreal-agent.md)
  
:rocket: **A3C agent: Asynchronous Methods for Deep Reinforcement Learning**
  - [[arXiv](https://arxiv.org/abs/1602.01783v2)], [[pdf](https://arxiv.org/pdf/1602.01783v2.pdf)]
  - Mnih et al.; Google DeepMind
  - :pencil: [**Notes**](./notes/a3c-agent.md)

## Year 2015
**Prioritized Experience Replay**
  - [[arXiv](https://arxiv.org/abs/1511.05952v4)], [[pdf](https://arxiv.org/pdf/1511.05952v4.pdf)]
  - Schaul et al.; Google DeepMind
  - :pencil: [**Notes**](./notes/prioritized-exp-replay.md)

:rocket: **Human-level control through deep reinforcement learning**
  - [[Nature](http://www.nature.com/nature/journal/v518/n7540/full/nature14236.html)]
  - Mnih et al.; Google Deepmind
  - :pencil: [**Notes**](./notes/dqn-agent.md)
